{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb92eb78-e8a2-4884-b6a0-98d379399db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eee31813-9959-4b21-a759-6d524f4ebe69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "os.chdir('/home/meiyih/Attention-Guided-Low-light-Image-Enhancement-with-Scene-Text-Restoration')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc4d0107-f194-4882-aed7-747ca159cec3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from skimage import exposure\n",
    "\n",
    "# dark_img_path = './dataset/Sony/short/00001_00_0.033s.png'\n",
    "\n",
    "# rgb = cv2.imread(dark_img_path, cv2.COLOR_BGR2RGB) * 150\n",
    "# img = np.uint8(np.minimum(rgb, 255.0))\n",
    "# cv2.imwrite('Sony_expose_example/dark_img_exposed150.png', img)\n",
    "\n",
    "\n",
    "# dark_img_path = './dataset/Sony/short/00001_00_0.04s.png'\n",
    "\n",
    "# rgb = cv2.imread(dark_img_path, cv2.COLOR_BGR2RGB) * 50\n",
    "# img = np.uint8(np.minimum(rgb, 255.0))\n",
    "# cv2.imwrite('Sony_expose_example/dark_img_exposed50.png', img)\n",
    "\n",
    "\n",
    "dark_img_path = './dataset/SID/Sony/test/short/10054_00_0.1s.png'\n",
    "\n",
    "rgb = cv2.imread(dark_img_path, cv2.COLOR_BGR2RGB) * 50\n",
    "img = np.uint8(np.minimum(rgb, 255.0))\n",
    "cv2.imwrite('dark_img_exposed.png', img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91926ac0-ff20-42cd-8b4f-ac6da1d5f59a",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = '/home/meiyih/BiSeNet_text_seg/datasets'\n",
    "\n",
    "imgs = os.listdir(os.path.join(DATASET_PATH, 'masks'))\n",
    "train, val = train_test_split(imgs, train_size=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f55b06e3-2392-4505-af97-7f66e4b736f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.c_[list(map(lambda x: os.path.join('syn_1.0-2.0_low_input', x), train))]\n",
    "Y_train = np.c_[list(map(lambda x: os.path.join('masks', x), train))]\n",
    "\n",
    "X_val = np.c_[list(map(lambda x: os.path.join('syn_1.0-2.0_low_input', x), val))]\n",
    "Y_val = np.c_[list(map(lambda x: os.path.join('masks', x), val))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ecd96a61-bc4a-4352-9f58-3341ba1356da",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_annotation = '\\n'.join(list(map(lambda x: ','.join(x), np.c_[X_train, Y_train])))\n",
    "val_annotation = '\\n'.join(list(map(lambda x: ','.join(x), np.c_[X_val, Y_val])))\n",
    "\n",
    "if not os.path.isdir('/home/meiyih/BiSeNet_text_seg/datasets/customDataset'):\n",
    "  os.mkdir('/home/meiyih/BiSeNet_text_seg/datasets/customDataset')\n",
    "\n",
    "with open('/home/meiyih/BiSeNet_text_seg/datasets/customDataset/train.txt', 'w') as f:\n",
    "  f.write(train_annotation)\n",
    "\n",
    "with open('/home/meiyih/BiSeNet_text_seg/datasets/customDataset/val.txt', 'w') as f:\n",
    "  f.write(val_annotation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2992491c-dee3-4080-b710-cee5d62889d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = \"\"\"cfg = dict(\n",
    "    model_type='bisenetv1',\n",
    "    n_cats=2,\n",
    "    num_aux_heads=2,\n",
    "    lr_start=1e-2,\n",
    "    weight_decay=5e-4,\n",
    "    warmup_iters=1000,\n",
    "    max_iter=80000,\n",
    "    dataset='CustomDataset',\n",
    "    im_root='/media/meiyih/meiyih_datasets/BiSeNet_text_seg/datasets',\n",
    "    train_im_anns='./datasets/customDataset/train.txt',\n",
    "    val_im_anns='./datasets/customDataset/val.txt',\n",
    "    scales=[0.75, 2.],\n",
    "    cropsize=[1024, 1024],\n",
    "    eval_crop=[1024, 1024],\n",
    "    eval_scales=[0.5, 0.75, 1.0, 1.25, 1.5, 1.75],\n",
    "    ims_per_gpu=8,\n",
    "    eval_ims_per_gpu=2,\n",
    "    use_fp16=True,\n",
    "    use_sync_bn=False,\n",
    "    respth='./res',\n",
    ")\"\"\"\n",
    "\n",
    "with open('/home/meiyih/BiSeNet_text_seg/configs/bisenetv1_customDataset.py', 'w') as f:\n",
    "  f.write(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8d716fc8-a496-422b-981e-d5583eb44ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "customDataset = '''#!/usr/bin/python\n",
    "# -*- encoding: utf-8 -*-\n",
    "\n",
    "import os\n",
    "import os.path as osp\n",
    "import json\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.distributed as dist\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "import lib.transform_cv2 as T\n",
    "from lib.sampler import RepeatedDistSampler\n",
    "from lib.base_dataset import BaseDataset\n",
    "\n",
    "labels_info =[\n",
    "{'name':\"background\",\"id\":0,\"color\":[0,0,0],\"trainId\":0},\n",
    "{'name':\"target\",\"id\":1,\"color\":[255,255,255],\"trainId\":1}\n",
    "]\n",
    "\n",
    "class CustomDataset(BaseDataset):\n",
    "    def __init__(self, dataroot, annpath, trans_func=None, mode='train'):\n",
    "        super(CustomDataset, self).__init__(\n",
    "                dataroot, annpath, trans_func, mode)\n",
    "        self.n_cats = 2\n",
    "        self.lb_ignore = 255\n",
    "        self.lb_map = np.arange(256).astype(np.uint8)\n",
    "        for el in labels_info:\n",
    "            self.lb_map[el['id']] = el['trainId']\n",
    "\n",
    "        self.to_tensor = T.ToTensor(\n",
    "            mean=(0.3257, 0.3690, 0.3223), # city, rgb\n",
    "            std=(0.2112, 0.2148, 0.2115),\n",
    "        )'''\n",
    "\n",
    "with open('/home/meiyih/BiSeNet_text_seg/lib/customDataset.py', 'w') as f:\n",
    "  f.write(customDataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "429ab808-98b0-4f8c-bb52-7f9b4249d35f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/meiyih/BiSeNet_text_seg\n"
     ]
    }
   ],
   "source": [
    "%cd BiSeNet_text_seg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "28ecc77b-abf6-43e9-b723-c3fa4c99070d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/meiyih/BiSeNet_text_seg/tools/train_amp.py\", line 53, in <module>\n",
      "    cfg = set_cfg_from_file(args.config)\n",
      "  File \"/home/meiyih/BiSeNet_text_seg/./configs/__init__.py\", line 15, in set_cfg_from_file\n",
      "    spec_loader = spec.loader.exec_module(cfg_file)\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 846, in exec_module\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 982, in get_code\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 1039, in get_data\n",
      "FileNotFoundError: [Errno 2] No such file or directory: 'configs/bisnetv1_customDataset.py'\n",
      "Killing subprocess 103293\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/meiyih/anaconda3/envs/pix_clone2/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/home/meiyih/anaconda3/envs/pix_clone2/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/home/meiyih/anaconda3/envs/pix_clone2/lib/python3.9/site-packages/torch/distributed/launch.py\", line 340, in <module>\n",
      "    main()\n",
      "  File \"/home/meiyih/anaconda3/envs/pix_clone2/lib/python3.9/site-packages/torch/distributed/launch.py\", line 326, in main\n",
      "    sigkill_handler(signal.SIGTERM, None)  # not coming back\n",
      "  File \"/home/meiyih/anaconda3/envs/pix_clone2/lib/python3.9/site-packages/torch/distributed/launch.py\", line 301, in sigkill_handler\n",
      "    raise subprocess.CalledProcessError(returncode=last_return_code, cmd=cmd)\n",
      "subprocess.CalledProcessError: Command '['/home/meiyih/anaconda3/envs/pix_clone2/bin/python', '-u', 'tools/train_amp.py', '--local_rank=0', '--config', 'configs/bisnetv1_customDataset.py']' returned non-zero exit status 1.\n"
     ]
    }
   ],
   "source": [
    "!python -m torch.distributed.launch --nproc_per_node=1 tools/train_amp.py --config configs/bisnetv1_customDataset.py "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "336ca5f9-f30b-4357-ae43-a956fe43ba77",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/python\n",
    "# -*- encoding: utf-8 -*-\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '.')\n",
    "import os\n",
    "import os.path as osp\n",
    "import random\n",
    "import logging\n",
    "import time\n",
    "import argparse\n",
    "import numpy as np\n",
    "from tabulate import tabulate\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.distributed as dist\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.cuda.amp as amp\n",
    "import torchvision\n",
    "from lib.models import model_factory\n",
    "from configs import set_cfg_from_file\n",
    "from lib.get_dataloader import get_data_loader\n",
    "from evaluate import eval_model\n",
    "from lib.ohem_ce_loss import OhemCELoss\n",
    "from lib.lr_scheduler import WarmupPolyLrScheduler\n",
    "from lib.meters import TimeMeter, AvgMeter\n",
    "from lib.logger import setup_logger, print_log_msg\n",
    "from pytorchtools import EarlyStopping\n",
    "\n",
    "from pytorch_msssim import ssim, ms_ssim\n",
    "\n",
    "## fix all random seeds\n",
    "#  torch.manual_seed(123)\n",
    "#  torch.cuda.manual_seed(123)\n",
    "#  np.random.seed(123)\n",
    "#  random.seed(123)\n",
    "#  torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = True\n",
    "#  torch.multiprocessing.set_sharing_strategy('file_system')\n",
    "\n",
    "#torchrun --standalone --nnodes=1 --nproc_per_node=1 tools/train_amp.py  YOUR_TRAINING_SCRIPT.py (--config configs/bisenetv1_customDataset.py)\n",
    "\n",
    "\n",
    "def parse_args():\n",
    "    parse = argparse.ArgumentParser()\n",
    "    parse.add_argument('--local_rank', dest='local_rank', type=int, default=-1,)\n",
    "    parse.add_argument('--port', dest='port', type=int, default=44557,)\n",
    "    parse.add_argument('--config', dest='config', type=str,\n",
    "            default='configs/bisenetv2.py',)\n",
    "    parse.add_argument('--finetune-from', type=str, default=None,)\n",
    "    return parse.parse_args()\n",
    "\n",
    "args = parse_args()\n",
    "cfg = set_cfg_from_file(args.config)\n",
    "\n",
    "\n",
    "\n",
    "def MAELoss(out_image, gt_image):\n",
    "    return torch.mean(torch.abs(out_image - gt_image))\n",
    "    \n",
    "def MS_SSIMLoss(out_image, gt_image):\n",
    "    return 1 - ms_ssim(out_image, gt_image, data_range=1, size_average=True)    \n",
    "\n",
    "def set_model():\n",
    "    logger = logging.getLogger()\n",
    "    net = model_factory[cfg.model_type](cfg.n_cats)\n",
    "    if not args.finetune_from is None:\n",
    "        logger.info(f'load pretrained weights from {args.finetune_from}')\n",
    "        net.load_state_dict(torch.load(args.finetune_from, map_location='cpu'))\n",
    "    if cfg.use_sync_bn: net = nn.SyncBatchNorm.convert_sync_batchnorm(net)\n",
    "    net.cuda()\n",
    "    net.train()\n",
    "    #criteria_pre = MAELoss()\n",
    "    #criteria_aux = [MS_SSIMLoss() for _ in range(cfg.num_aux_heads)]\n",
    "    return net#, criteria_pre, criteria_aux\n",
    "\n",
    "\n",
    "def set_optimizer(model):\n",
    "    if hasattr(model, 'get_params'):\n",
    "        wd_params, nowd_params, lr_mul_wd_params, lr_mul_nowd_params = model.get_params()\n",
    "        #  wd_val = cfg.weight_decay\n",
    "        wd_val = 0\n",
    "        params_list = [\n",
    "            {'params': wd_params, },\n",
    "            {'params': nowd_params, 'weight_decay': wd_val},\n",
    "            {'params': lr_mul_wd_params, 'lr': cfg.lr_start * 10},\n",
    "            {'params': lr_mul_nowd_params, 'weight_decay': wd_val, 'lr': cfg.lr_start * 10},\n",
    "        ]\n",
    "    else:\n",
    "        wd_params, non_wd_params = [], []\n",
    "        for name, param in model.named_parameters():\n",
    "            if param.dim() == 1:\n",
    "                non_wd_params.append(param)\n",
    "            elif param.dim() == 2 or param.dim() == 4:\n",
    "                wd_params.append(param)\n",
    "        params_list = [\n",
    "            {'params': wd_params, },\n",
    "            {'params': non_wd_params, 'weight_decay': 0},\n",
    "        ]\n",
    "    optim = torch.optim.SGD(\n",
    "        params_list,\n",
    "        lr=cfg.lr_start,\n",
    "        momentum=0.9,\n",
    "        weight_decay=cfg.weight_decay,\n",
    "    )\n",
    "    return optim\n",
    "\n",
    "\n",
    "def set_model_dist(net):\n",
    "    local_rank = dist.get_rank()\n",
    "    #local_rank = int(os.environ[\"LOCAL_RANK\"])\n",
    "    net = nn.parallel.DistributedDataParallel(\n",
    "        net,\n",
    "        device_ids=[local_rank, ],\n",
    "        #  find_unused_parameters=True,\n",
    "        output_device=local_rank\n",
    "        )\n",
    "    return net\n",
    "\n",
    "\n",
    "def set_meters():\n",
    "    time_meter = TimeMeter(cfg.max_iter)\n",
    "    loss_meter = AvgMeter('loss')\n",
    "    loss_pre_meter = AvgMeter('loss_prem')\n",
    "    loss_aux_meters = [AvgMeter('loss_aux{}'.format(i))\n",
    "            for i in range(cfg.num_aux_heads)]\n",
    "    return time_meter, loss_meter, loss_pre_meter, loss_aux_meters\n",
    "\n",
    "\n",
    "\n",
    "def train():\n",
    "    logger = logging.getLogger()\n",
    "    is_dist = dist.is_initialized()\n",
    "\n",
    "    ## dataset\n",
    "    dl = get_data_loader(cfg, mode='train', distributed=is_dist)\n",
    "\n",
    "    ## model\n",
    "    net = set_model()\n",
    "\n",
    "    ## optimizer\n",
    "    optim = set_optimizer(net)\n",
    "\n",
    "    ## mixed precision training\n",
    "    scaler = amp.GradScaler()\n",
    "\n",
    "    ## ddp training\n",
    "    net = set_model_dist(net)\n",
    "\n",
    "    ## meters\n",
    "    time_meter, loss_meter, loss_pre_meter, loss_aux_meters = set_meters()\n",
    "\n",
    "    ## lr scheduler\n",
    "    #lr_schdr = WarmupPolyLrScheduler(optim, power=0.9,\n",
    "        #max_iter=cfg.max_iter, warmup_iter=cfg.warmup_iters,\n",
    "        #warmup_ratio=0.1, warmup='exp', last_epoch=-1,)\n",
    "        \n",
    "        \n",
    "        # Define Scheduler\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optim, factor=0.1, patience=10, verbose=True)    \n",
    "    \n",
    "    # Define early_stopping\n",
    "    early_stopping = EarlyStopping(patience=20, verbose=True)\n",
    "    \n",
    "    step=0\n",
    "    logit_hist=[]\n",
    "    logit0_hist=[]\n",
    "    logit1_hist=[]\n",
    "\n",
    "    ## train loop\n",
    "    for it, (im, lb) in enumerate(dl):\n",
    "        losses = []\n",
    "        im = im.cuda()\n",
    "        lb = lb.cuda()\n",
    "        #print('im shape : ',im.shape,'lb shape : ',lb.shape)\n",
    "\t\n",
    "        optim.zero_grad()\n",
    "        with amp.autocast(enabled=cfg.use_fp16):\n",
    "            \n",
    "            logits, *logits_aux = net(im)\n",
    "            #print(f'dtype of logits : {logits.dtype} , dtype of logits_aux[0] : {logits_aux[0].dtype},dtype of logits_aux[1] : {logits_aux[1].dtype}, dtype of img :{im.dtype}, dtype of rg :{lb.dtype}')\n",
    "            #print('net output shape : ',logits.shape)\n",
    "            #print(f'.max() of logits : {logits.max()} , dtype of logits_aux[0] : {logits_aux[0].max()},dtype of logits_aux[1] : {logits_aux[1].max()}, dtype of img :{im.max()}, dtype of rg :{lb.max()}')\n",
    "            #print(f'.min() of logits : {logits.min()} , dtype of logits_aux[0] : {logits_aux[0].min()},dtype of logits_aux[1] : {logits_aux[1].min()}, dtype of img :{im.min()}, dtype of rg :{lb.min()}')\n",
    "            #print('net output shape : ',logits.shape)\n",
    "            #logits=torch.div(logits, 255)\n",
    "            #logits=torch.clamp(logits, min=0.0, max=1.0)\n",
    "            #logits_aux[0]=torch.div(logits_aux[0], 255)\n",
    "            #logits_aux[0]=torch.clamp(logits_aux[0], min=0.0, max=1.0)\n",
    "            #logits_aux[1]=torch.div(logits_aux[1], 255)\n",
    "            #logits_aux[1]=torch.clamp(logits_aux[1], min=0.0, max=1.0)\n",
    "            #print(f'after ............max() of logits : {logits.max()} , dtype of logits_aux[0] : {logits_aux[0].max()},dtype of logits_aux[1] : {logits_aux[1].max()}, dtype of img :{im.max()}, dtype of rg :{lb.max()}')\n",
    "            #print(f'after .............min() of logits : {logits.min()} , dtype of logits_aux[0] : {logits_aux[0].min()},dtype of logits_aux[1] : {logits_aux[1].min()}, dtype of img :{im.min()}, dtype of rg :{lb.min()}')\n",
    "\n",
    "            logits= logits.type_as(lb)\n",
    "            logits_aux[0]=logits_aux[0].type_as(lb)\n",
    "            logits_aux[1]=logits_aux[1].type_as(lb)\n",
    "        \n",
    "            #logits=torch.nn.functional.sigmoid(logits)\n",
    "            #logits_aux[0]=torch.nn.functional.sigmoid(logits_aux[0])\n",
    "            #logits_aux[1]=torch.nn.functional.sigmoid(logits_aux[1])\n",
    "            loss_pre = MAELoss(logits, lb)\n",
    "            \n",
    "            #loss_aux1 = MS_SSIMLoss(logits_aux[0], lb)\n",
    "            loss_aux1 = MAELoss(logits_aux[0], lb)\n",
    "            loss_aux2 = MAELoss(logits_aux[1], lb)\n",
    "            loss_aux=[loss_aux1,loss_aux2]\n",
    "            loss = 1.005*loss_pre + 0.555*sum(loss_aux)\n",
    "            losses.append(loss.item())\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optim)\n",
    "        scaler.update()\n",
    "        torch.cuda.synchronize()\n",
    "\n",
    "        time_meter.update()\n",
    "        loss_meter.update(loss.item())\n",
    "        loss_pre_meter.update(loss_pre.item())\n",
    "        _ = [mter.update(lss.item()) for mter, lss in zip(loss_aux_meters, loss_aux)]\n",
    "\n",
    "\n",
    "        ## print training log message #end of one epoch is 125\n",
    "        if (it + 1) % 125 == 0: #end of 1 epoch \n",
    "            #lr = lr_schdr.get_lr()\n",
    "            mean_loss = sum(losses) / len(losses)\n",
    "            scheduler.step(mean_loss)\n",
    "            lr = optim.param_groups[0]['lr']\n",
    "            print('epoch :',((it+1)/125) , '/n lr is :' ,(optim.param_groups[0]['lr']) , '/n mean loss is : ', (mean_loss))\n",
    "            print_log_msg(it, cfg.max_iter, lr, time_meter, loss_meter,loss_pre_meter, loss_aux_meters)\n",
    "            #save some output imges\n",
    "            \n",
    "            torchvision.utils.save_image(im , f\"./saved_images/low_light_img_{step}.png\")       \n",
    "            torchvision.utils.save_image(lb , f\"./saved_images/rgb_img_{step}.png\")\n",
    "            torchvision.utils.save_image(logits , f\"./saved_images/rgb_pred_{step}.png\")\n",
    "            \n",
    "            # early_stopping needs the validation loss to check if it has decresed, \n",
    "            # and if it has, it will make a checkpoint of the current model\n",
    "            early_stopping(mean_loss, net)\n",
    "            \n",
    "            if early_stopping.early_stop:\n",
    "            \tprint(\"Early stopping\")\n",
    "\n",
    "            \tsave_pth = osp.join(cfg.respth, 'model_final.pth')\n",
    "            \tlogger.info('\\nsave models to {}'.format(save_pth))\n",
    "            \tstate = net.module.state_dict()\n",
    "            \tif dist.get_rank() == 0: torch.save(state, save_pth)\n",
    "\n",
    "            \tlogger.info('\\nevaluating the final model')\n",
    "            \ttorch.cuda.empty_cache()\n",
    "            \theads, mious = eval_model(cfg, net.module)\n",
    "            \tlogger.info(tabulate([mious, ], headers=heads, tablefmt='orgtbl'))\n",
    "            \t\n",
    "            \tPath(dir_checkpoint).mkdir(parents=True, exist_ok=True)\n",
    "            \ttorch.save(net.state_dict(), str(dir_checkpoint / 'real_checkpoint_epoch{}.pth'.format(((it+1)/250))))\n",
    "            \tlogging.info(f'Checkpoint {((it+1)/250)} saved!')\n",
    "            \t\n",
    "    \n",
    "            \tbreak #early stopping applied\n",
    "        \n",
    "            \n",
    "            step+=1\n",
    "        \n",
    "        if (it + 1) % 125 == 0: #end of 1 epoch \n",
    "            logit_hist=[]        \n",
    "                ## save the model and evaluate the result\n",
    "        if (it)% 6250 == 0:            \n",
    "            save_pth = osp.join(cfg.respth, 'model_final'+str(it)+'.pth')\n",
    "            logger.info('\\nsave models to {}'.format(save_pth))\n",
    "            state = net.module.state_dict()\n",
    "            if dist.get_rank() == 0: torch.save(state, save_pth)\n",
    "            \n",
    "    ## dump the final model and evaluate the result\n",
    "    save_pth = osp.join(cfg.respth, 'model_the_final.pth')\n",
    "    logger.info('\\nsave models to {}'.format(save_pth))\n",
    "    state = net.module.state_dict()\n",
    "    if dist.get_rank() == 0: torch.save(state, save_pth)\n",
    "\n",
    "    logger.info('\\nevaluating the final model')\n",
    "    torch.cuda.empty_cache()\n",
    "    heads, mious = eval_model(cfg, net.module)\n",
    "    logger.info(tabulate([mious, ], headers=heads, tablefmt='orgtbl'))\n",
    "\n",
    "    return\n",
    "       \n",
    "def main():\n",
    "    torch.cuda.set_device(args.local_rank)\n",
    "    dist.init_process_group(\n",
    "        backend='nccl',\n",
    "        init_method='tcp://127.0.0.1:{}'.format(args.port),\n",
    "        world_size=torch.cuda.device_count(),\n",
    "        rank=args.local_rank\n",
    "    )\n",
    "    if not osp.exists(cfg.respth): os.makedirs(cfg.respth)\n",
    "    setup_logger(f'{cfg.model_type}-{cfg.dataset.lower()}-train', cfg.respth)\n",
    "    train()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3fa43ee3-82a2-4ca2-8acc-bfbf228dd501",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw as D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "362ebfba-4792-43b6-8ffb-de159f2247bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "i=Image.open(\"/home/meiyih/Attention-Guided-Low-light-Image-Enhancement-with-Scene-Text-Restoration/dataset/SID/Sony/test/long/10011_00_10s.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1df5f1cc-70cd-4580-b5f7-0b60035fc997",
   "metadata": {},
   "outputs": [],
   "source": [
    "draw=D.Draw(i)\n",
    "draw.rectangle([(1930,2122),(1987,2155)],outline=\"white\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7fd24a73-a41b-4076-932e-c8751803b09b",
   "metadata": {},
   "outputs": [],
   "source": [
    "draw=D.Draw(i)\n",
    "draw.rectangle([(2202,2570),(2351,2821)],outline=\"white\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4f4b623d-d695-4628-9bf1-ebf1e731bf72",
   "metadata": {},
   "outputs": [],
   "source": [
    "draw=D.Draw(i)\n",
    "draw.rectangle([(2156,2689),(2259,2813)],outline=\"white\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b770e4de-0b0e-4fbb-80db-5907fbe1bb92",
   "metadata": {},
   "outputs": [],
   "source": [
    "draw=D.Draw(i)\n",
    "draw.rectangle([(2478,20),(2702,37)],outline=\"white\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "20152f53-64cb-4f2f-91ab-dfc5cac6e52b",
   "metadata": {},
   "outputs": [],
   "source": [
    "draw=D.Draw(i)\n",
    "draw.rectangle([(2598,86),(2676,116)],outline=\"white\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c701de57-a323-400f-9791-909487d2e4cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "draw=D.Draw(i)\n",
    "draw.rectangle([(2523,94),(2598,118)],outline=\"white\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9b9534eb-daeb-4125-9570-99329308ad7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "i.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef3dd44c-08df-4d0d-814c-d497d01881a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
